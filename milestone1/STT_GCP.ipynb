{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'client_service_key.json'\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/Users/taeyoungchang/.ssh/tchang3_speech_to_text.json\"\n",
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/Users/taeyoungchang/.ssh/iitp-class-6a6fe04e5bb2.json\"\n",
    "speech_client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1 & 2. Transcribe Local Media File \n",
    "# File Size: < 10mbs, length < 1 minute\n",
    "\n",
    "## Step 1. Load the media files\n",
    "# media_file_name_mp3 = 'demo audio.mp3'\n",
    "# media_file_name_wav = 'demo audio.wav'\n",
    "\n",
    "media_file_name_wav = \"/Users/taeyoungchang/Desktop/StudioProject/sample_data/clean_fileid_20.wav\"\n",
    "media_file_name_flac = \"/Users/taeyoungchang/Desktop/StudioProject/sample_data/LibriSpeech/test-clean/61/70968/61-70968-0000.flac\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(media_file_name_mp3, 'rb') as f1:\n",
    "#     byte_data_mp3 = f1.read()\n",
    "# audio_mp3 = speech.RecognitionAudio(content=byte_data_mp3)\n",
    "\n",
    "with open(media_file_name_wav, 'rb') as f1:\n",
    "    byte_data_wav = f1.read()\n",
    "audio_wav = speech.RecognitionAudio(content=byte_data_wav)\n",
    "\n",
    "with open(media_file_name_flac, 'rb') as f2:\n",
    "    byte_data_flac = f2.read()\n",
    "audio_flac = speech.RecognitionAudio(content=byte_data_flac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2. Configure Media Files Output\n",
    "# config_mp3 = speech.RecognitionConfig(\n",
    "#     sample_rate_hertz=48000,\n",
    "#     enable_automatic_punctuation=True,\n",
    "#     language_code='en-US'\n",
    "# )\n",
    "\n",
    "config_wav = speech.RecognitionConfig(\n",
    "    sample_rate_hertz=16000,\n",
    "    enable_automatic_punctuation=True,\n",
    "    language_code='en-US',\n",
    "    audio_channel_count=1\n",
    ")\n",
    "\n",
    "config_flac = speech.RecognitionConfig(\n",
    "    sample_rate_hertz=16000,\n",
    "    enable_automatic_punctuation=True,\n",
    "    language_code='en-US'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"Unfortunately owns no films. The battery median grade equivalent was used in data analysis. In this study, the batting average of 16s out of 7 in.\"\n",
      "    confidence: 0.922411859\n",
      "  }\n",
      "  result_end_time {\n",
      "    seconds: 9\n",
      "    nanos: 960000000\n",
      "  }\n",
      "  language_code: \"en-us\"\n",
      "}\n",
      "total_billed_time {\n",
      "  seconds: 10\n",
      "}\n",
      "\n",
      "results {\n",
      "  alternatives {\n",
      "    transcript: \"He began a confused complaint against the wizard, who would vanish behind the curtain on the left.\"\n",
      "    confidence: 0.939540386\n",
      "  }\n",
      "  result_end_time {\n",
      "    seconds: 4\n",
      "    nanos: 870000000\n",
      "  }\n",
      "  language_code: \"en-us\"\n",
      "}\n",
      "total_billed_time {\n",
      "  seconds: 5\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Step 3. Transcribing the RecognitionAudio objects\n",
    "# response_standard_mp3 = speech_client.recognize(\n",
    "#     config=config_mp3,\n",
    "#     audio=audio_mp3\n",
    "# )\n",
    "\n",
    "response_standard_wav = speech_client.recognize(\n",
    "    config=config_wav,\n",
    "    audio=audio_wav\n",
    ")\n",
    "response_standard_flac = speech_client.recognize(\n",
    "    config=config_flac,\n",
    "    audio=audio_flac\n",
    ")\n",
    "\n",
    "# print(response_standard_mp3)\n",
    "print(response_standard_wav)\n",
    "print(response_standard_flac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDenied",
     "evalue": "403 tchang3-speech-to-text@windy-gizmo-374321.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object. Permission 'storage.objects.get' denied on resource (or it may not exist).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torchBegin/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:72\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torchBegin/lib/python3.9/site-packages/grpc/_channel.py:946\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    944\u001b[0m state, call, \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_blocking(request, timeout, metadata, credentials,\n\u001b[1;32m    945\u001b[0m                               wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0m \u001b[39mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torchBegin/lib/python3.9/site-packages/grpc/_channel.py:849\u001b[0m, in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 849\u001b[0m     \u001b[39mraise\u001b[39;00m _InactiveRpcError(state)\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"tchang3-speech-to-text@windy-gizmo-374321.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object. Permission 'storage.objects.get' denied on resource (or it may not exist).\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.250.80.106:443 {grpc_message:\"tchang3-speech-to-text@windy-gizmo-374321.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object. Permission \\'storage.objects.get\\' denied on resource (or it may not exist).\", grpc_status:7, created_time:\"2023-01-12T17:52:19.686037-05:00\"}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb ì…€ 7\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# config_wav_enhanced = speech.RecognitionConfig(\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#     sample_rate_hertz=48000,\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#     enable_automatic_punctuation=True,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m#     model='video'\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m config_m4a_enhanced \u001b[39m=\u001b[39m speech\u001b[39m.\u001b[39mRecognitionConfig(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     sample_rate_hertz\u001b[39m=\u001b[39m\u001b[39m44100\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     enable_automatic_punctuation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvideo\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m operation \u001b[39m=\u001b[39m speech_client\u001b[39m.\u001b[39;49mlong_running_recognize(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     config\u001b[39m=\u001b[39;49mconfig_m4a_enhanced,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     audio\u001b[39m=\u001b[39;49mlong_audi_m4a\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m response \u001b[39m=\u001b[39m operation\u001b[39m.\u001b[39mresult(timeout\u001b[39m=\u001b[39m\u001b[39m200\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/taeyoungchang/Desktop/StudioProject/STT_GCP.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(response)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torchBegin/lib/python3.9/site-packages/google/cloud/speech_v1/services/speech/client.py:698\u001b[0m, in \u001b[0;36mSpeechClient.long_running_recognize\u001b[0;34m(self, request, config, audio, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    695\u001b[0m rpc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39m_wrapped_methods[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39mlong_running_recognize]\n\u001b[1;32m    697\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 698\u001b[0m response \u001b[39m=\u001b[39m rpc(\n\u001b[1;32m    699\u001b[0m     request,\n\u001b[1;32m    700\u001b[0m     retry\u001b[39m=\u001b[39;49mretry,\n\u001b[1;32m    701\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    702\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadata,\n\u001b[1;32m    703\u001b[0m )\n\u001b[1;32m    705\u001b[0m \u001b[39m# Wrap the response in an operation future.\u001b[39;00m\n\u001b[1;32m    706\u001b[0m response \u001b[39m=\u001b[39m operation\u001b[39m.\u001b[39mfrom_gapic(\n\u001b[1;32m    707\u001b[0m     response,\n\u001b[1;32m    708\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport\u001b[39m.\u001b[39moperations_client,\n\u001b[1;32m    709\u001b[0m     cloud_speech\u001b[39m.\u001b[39mLongRunningRecognizeResponse,\n\u001b[1;32m    710\u001b[0m     metadata_type\u001b[39m=\u001b[39mcloud_speech\u001b[39m.\u001b[39mLongRunningRecognizeMetadata,\n\u001b[1;32m    711\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torchBegin/lib/python3.9/site-packages/google/api_core/gapic_v1/method.py:113\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, *args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     metadata\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata)\n\u001b[1;32m    111\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m metadata\n\u001b[0;32m--> 113\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped_func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/torchBegin/lib/python3.9/site-packages/google/api_core/grpc_helpers.py:74\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m callable_(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m grpc\u001b[39m.\u001b[39mRpcError \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_grpc_error(exc) \u001b[39mfrom\u001b[39;00m \u001b[39mexc\u001b[39;00m\n",
      "\u001b[0;31mPermissionDenied\u001b[0m: 403 tchang3-speech-to-text@windy-gizmo-374321.iam.gserviceaccount.com does not have storage.objects.get access to the Google Cloud Storage object. Permission 'storage.objects.get' denied on resource (or it may not exist)."
     ]
    }
   ],
   "source": [
    "# Example 3: Transcribing a long media file\n",
    "# media_uri = 'gs://speech-to-text-media-files/Steve Job 2005 Commencement Speech.wav'\n",
    "media_uri = 'gs://tchangs_speech_to_text_media_files/TED_MattCutts_2011_Univ.m4a'\n",
    "long_audi_m4a = speech.RecognitionAudio(uri=media_uri)\n",
    "\n",
    "# config_wav_enhanced = speech.RecognitionConfig(\n",
    "#     sample_rate_hertz=48000,\n",
    "#     enable_automatic_punctuation=True,\n",
    "#     language_code='en-US',\n",
    "#     use_enhanced=True,\n",
    "#     model='video'\n",
    "# )\n",
    "config_m4a_enhanced = speech.RecognitionConfig(\n",
    "    sample_rate_hertz=44100,\n",
    "    enable_automatic_punctuation=True,\n",
    "    language_code='en-US',\n",
    "    use_enhanced=True,\n",
    "    model='video'\n",
    ")\n",
    "\n",
    "operation = speech_client.long_running_recognize(\n",
    "    config=config_m4a_enhanced,\n",
    "    audio=long_audi_m4a\n",
    ")\n",
    "response = operation.result(timeout=200)\n",
    "print(response)\n",
    "\n",
    "for result in response.results:\n",
    "    print(result.alternatives[0].transcript)\n",
    "    print(result.alternatives[0].confidence)\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchBegin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71a9b4293f9fa7829c177dfcaeafa0231cf316c9d8de237aca40a05e38913fee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
